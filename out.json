{
    "title": "歌詞没入型身体的音楽体験を可能とする光学透過式MR環境LyricBathe",
    "abstract": "LyricBathe は、HoloLens 2 を用いて歌詞を楽曲と同期して空間に表示するインタラクティブなMR 環境である。24 種の異なるモードによる歌詞体験の違いを、注視箇所と頭部位置データをもとに調査した。予備実験と本実験を通して、モードによって視線行動が一貫して誘発される場合と、個人差が表れやすい場合があることが明らかになった。また、曲調とモードの組み合わせによって体験スタイルが変化する傾向も確認された。これらの知見は、ユーザ特性に応じたMR 歌詞体験の最適化や、より没入感の高い体験設計に向けた基盤的知見を提供する。",
    "keywords": [],
    "sections": [
        {
            "number": "1.",
            "part_name": "はじめに",
            "paragraphs_below": [
                {
                    "content": "歌詞は音楽を豊かにする詩的表現であり、メディア技術の発展とともに歌詞カード、音楽再生アプリケーションのカラオケ的な歌詞表示、より多様なアニメーション（キネティックタイポグラフィ）を含むリリックビデオ、インタラクティブな「リリックアプリ(lyric app)」のように様々な視覚表現として楽しまれてきた。加藤ら[1] は、リリックアプリを提唱するとともに、その開発を支援するLyricApp Framework を提供し、楽曲の再生と同期した多様な歌詞体験を実現するアプリケーション開発を支援してきた。しかし、既存のリリックアプリの多くは、パーソナルコンピュータやスマートフォンなどの一般的な矩形ディスプレイを前提としている。",
                    "list_items": [],
                    "is_enumrated": false
                },
                {
                    "content": "一方、本研究では、歌詞を身体的に体験する没入型の新たな音楽鑑賞スタイルを可能にすることを目指し、ユーザが光学透過型ヘッドマウントディスプレイ（HoloLens 2）を用いた複合現実（MR）環境内で歌詞を楽しめるシステム「LyricBathe」を開発してきた。本システムでは、歌詞は楽曲の進行と同期する3DCG オブジェクトとして表示され、ユーザの身体や現実世界の物理的なオブジェクトとインタラクションすることが可能である。例えば、文字が体から飛び出してきたり、文字を浴びられるように落ちてきたり、ユーザの周りを囲むように文字が表示されたりするような身体的なインタラクションを実現するモードを用意しており、歌詞に「浸る」ような歌詞体験が可能である(図1)。",
                    "list_items": [],
                    "is_enumrated": false
                },
                {
                    "content": "これまでに、歌詞の文字の大きさ、動き、表示タイミング、身体や現実世界とのインタラクションの方法などの表現方法（インタラクションプリミティブ）を様々に組み合わせた種々のモードを実装してきた。当初は、プロジェクトの初期段階で構築した8 つのモードについて注視箇所を計測するユーザ調査を実施した。しかし、いずれのモードが魅力的だと評価されているか、有意な結論を導くことはできなかった[2]。そこで、新たなモードの開発を継続し計24 種類のモードを実装し、歌詞没入型身体的音楽体験に寄与する基本的な要素をインタラクションプリミティブとして11 項目、定性的な議論をもとに同定した[3]。",
                    "list_items": [],
                    "is_enumrated": false
                },
                {
                    "content": "本論文では、各インタラクションプリミティブのユーザ体験への寄与や、楽曲の特徴による影響について調査するために、2 つのユーザ観察実験を行った。まず、1 曲の歌詞付き楽曲を用いて、1 名のユーザを対象に、LyricBathe の全24 種類のモードについて、注視行動や頭部運動といったユーザの行動を記録・分析する予備実験を行った。具体的には、実験で記録したデータについてモードごとのクラスタリングを行い、歌詞体験を構成するインタラクションプリミティブによるユーザ体験の変化を分析した。予備実験では、巨大な文字を表示するモードではユーザの頭部運動が大きくなるなど、インタラクションプリミティブが異なる行動特徴を誘起することが示唆された。続いて、予備実験で特徴的な行動が見られた8 種のモードにおいて、同一の歌詞を使用したロック調、ヒップホップ調、バラード調といった3 種類の楽曲を用いて、4 名のユーザを対象に本実験を実施した。本実験を通して、参加者や楽曲によって異なる行動の特徴がみられるモードが存在すること、定性的なインタビュー結果からは、静的な集中から動的な探索まで、参加者ごとに様々な評価軸が存在し、注視パターンにそれらが表れることが明らかとなった。",
                    "list_items": [],
                    "is_enumrated": false
                }
            ]
        },
        {
            "number": "2.",
            "part_name": "関連研究",
            "paragraphs_below": [
                {
                    "content": "さまざまなテキスト表現形式の中でも、歌詞の表現は、音楽の時間的進行によって制約を受ける形式として際立っている。テキストの動きを同期させたり、歌詞の特定の部分を強調したりすることで、音楽鑑賞体験をより豊かなものにすることができる。本章では、MR 環境におけるテキストのダイナミックな表現に関連する既存研究について概説する。音楽に付随する空間的な表現やインタラクティブな表現はさまざまな形で研究されてきたが、MR 環境でインタラクティブかつ身体的な体験を創出する研究は少なく、そうした表現を設計するための知見にも乏しい。",
                    "list_items": [],
                    "is_enumrated": false
                }
            ]
        },
        {
            "number": "2.1",
            "part_name": "キネティックタイポグラフィ",
            "paragraphs_below": [
                {
                    "content": "テキストに、動き、回転、変形を加えてアニメーションさせる視覚表現は、キネティックタイポグラフィと総称される。Shannon ら[4] は、1990 年代後半にはすでに、そのデザインの基礎となるいくつかの原則について論じている。30 年以上にわたる経験と知識の蓄積により、キネティックタイポグラフィは、歌詞が楽曲再生にあわせてタイミングよくアニメーションする動画（リリックビデオ）など、テキストのダイナミックな視覚表現を創り出す技術として広く利用されるようになった。キネティックタイポグラフィは主に二次元の動画として書き出される静的な視覚表現であり、ユーザ自身が自由に動き回れるような三次元のMR 環境にそのまま適用することはできない。",
                    "list_items": [],
                    "is_enumrated": false
                }
            ]
        },
        {
            "number": "2.2",
            "part_name": "楽曲再生と同期した歌詞表現",
            "paragraphs_below": [
                {
                    "content": "楽曲再生と同期した歌詞テキストの表示は、カラオケやリリックビデオでよく見られる。リリックアプリは、こうした表現にユーザとのインタラクションを加えた新たな歌詞駆動型の視覚表現である[1]。例えば、特定の楽曲の世界観を表現したVR 空間を体験できる拡張現実アプリ[*1]や、ユーザが画面上の歌詞を左右にドラッグ＆ドロップして楽曲の再生位置をコントロールできるインタラクティブなリリックビデオ[*2]などがある。また、身体性を伴う体験を提供するリリックアプリとして、スマートフォンのカメラで撮影した自撮り映像上で、口からリアルタイムに再生中の歌詞が湧き出てくるもの[*3]がある。ただし、これらの例があくまでパーソナルコンピュータやスマートフォンなどの平面的な矩形ディスプレイ上に表示されるものであるのに対し、本論文で取り組んでいる光学透過型ヘッドマウントディスプレイを使用する複合現実（MR）環境では、歌詞が直接知覚される現実世界の空間に重ねて表示されるため、考慮すべき要素が異なる。例えば、歌詞がユーザの身体や、家具、手持ちの物体、他の人物など周囲の物理的環境と相互作用することが考えられ、本研究ではこうした従来のキネティックタイポグラフィを中心とした歌詞表現を超える体験設計に有用な知見の創出を目指している。",
                    "list_items": [],
                    "is_enumrated": false
                }
            ]
        },
        {
            "number": "2.3",
            "part_name": "MR 環境でのテキスト体験",
            "paragraphs_below": [
                {
                    "content": "文字をMR 空間内で体験する既存研究は多数ある。例えば、物理的なオブジェクトと仮想のテキスト表示を組み合わせた文字表現として、横濱ら[5] の構築したMAVenReadがある。MAVenRead では、HoloLens 2 を装着して物理的な本を開くと、ほぼ白紙のページ端に印刷されたAR マーカが読み取られ、そのページ上に詩の文字が動的に重畳表示される。重畳表現される文字を一定方向に動かしたり、ゆっくりと回転させるなどのアニメーションにより、新たな読詩体験を実現している。また、VR やMR を用いて複数の文書を空間的に配置し、文書の潜在的な意味を抽出するような取り組みがある。Bandyopadhyay [6] は、VRヘッドマウントディスプレイを用いた文書の意味抽出のためのシステムとしてImmersive Space to Think (IST) というシステムを構築し、没入型3D 空間での文書の意味抽出プロセスの有用性について検証を行っている。Weizhouら[7] は、オフィス環境でのMR 技術を用いた文書の空間配置について、ユーザ中心デザイン研究を実施し、インタラクション手法を抽出している。しかしながら、これら既存のMR 環境における文字表現の手法は、動的に変わる音楽の進行に同期する形での歌詞表現と比べると、躍動感や時間厳密性といった点において、ユーザの体験が本質的に異なると考えられる。",
                    "list_items": [],
                    "is_enumrated": false
                }
            ]
        },
        {
            "number": "2.4",
            "part_name": "モーショングラフィックス",
            "paragraphs_below": [
                {
                    "content": "モーショングラフィックスはデータや画像をアニメーションで表示する映像ベースの情報表現手法の一つである。Amir ら[8] は、モーショングラフィックスを組み込んだ映像制作のためのオーサリングツールを配布し、モードがデザインプロセスに与える影響について調査した。プロのモーションデザイナーはカスタマイズできるオプションが多いことを好むなど、専門性の高さによってモードに求める要件が異なることを示すものだった。モーショングラフィックスは、あらかじめ映像をすべてデザインして制作する必要があり、動的に体験を創出する本研究とは体験のデザインが異なるものとなる。",
                    "list_items": [],
                    "is_enumrated": false
                }
            ]
        },
        {
            "number": "2.5",
            "part_name": "ジェネレイティブアート",
            "paragraphs_below": [
                {
                    "content": "ジェネレイティブアートは、数学的アルゴリズムとコンピュータプログラムを使用してデザインを生成するアートの一種である。David らは、ジェスチャと音声を使って複数人が同じジェネレイティブアートとインタラクションできるワイヤレスポータブルデバイスi-Cube を構築している[9]。i-Cube を通してユーザの物理的な動きや音声を読み取ることで、インタラクティブかつダイナミックな視覚表現をスクリーンに表示することが出来る。これに対してLyricBathe は、一人で音楽鑑賞を行うことを前提に構築しており、表示空間に関してもスクリーンのような平面ではなく、3 次元空間に歌詞の表示を行うことが特徴的である。",
                    "list_items": [],
                    "is_enumrated": false
                }
            ]
        },
        {
            "number": "2.6",
            "part_name": "空間的な音楽体験の拡張",
            "paragraphs_below": [
                {
                    "content": "音楽の物理空間内での表現に関しては、5.1ch のサラウンドや空間オーディオなどが一般化している。音楽を物理空間内でインタラクティブに楽しむ研究としてMiyagawaら[10] は、物理空間に音源を自在に配置して音楽鑑賞を行うシステムを構築している。この研究では、MR 環境でオーケストラの音の分布を空間にビジュアルとして表現し、各音源を空間に固定したり、ユーザが自由に配置しながらインタラクティブに音楽を楽しむ音楽体験を実現している。Jongik ら[11][12] の構築したSoundMist では、音を噴霧する音楽体験を実現している。物理的なスプレーを空間に噴霧することで、空間内に音源を配置し、霧と共に霧散していくような没入感のある空間的・聴覚的体験を作り出している。しかし、これらの空間的な音楽体験を拡張する既存研究は、あくまで音の体験を拡張するものであり、本研究で目指している楽曲本来の音楽的要素を損なわないような音楽体験とは異なると考えられる。",
                    "list_items": [],
                    "is_enumrated": false
                }
            ]
        },
        {
            "number": "3.",
            "part_name": "LyricBathe",
            "paragraphs_below": [
                {
                    "content": "LyricBatheは、光学透過式のMRデバイスであるHoloLens2を使用したMRシステムであり、歌詞を3DCGオブジェクトとしてMR環境内に、音楽の進行と同期しながら表示する。それに加えて、ユーザが身体を動かすことで歌詞とインタラクションすることができる。ユーザは、MP3 形式の楽曲と歌詞のテキストデータがあれば、LyricBathe の各モードを体験することができる。",
                    "list_items": [],
                    "is_enumrated": false
                },
                {
                    "content": "歌詞と音楽を同期させるために、LyricBathe はリリックビデオ・アプリの制作・配信支援プラットフォームであるTextAlive [13] と共通の歌詞タイミング解析技術を利用している。これにより、各文字の発音タイミング、各文字のフレーズID、各フレーズの終了タイミングをリスト化したCSV ファイルが生成される。このCSV ファイルは、Unity 上で動作するLyricBathe によって読み込まれ、同時に音楽の音声ファイルも再生される。LyricBathe は、歌詞表現の最も原始的な要素、すなわち歌詞の各フレーズと、各文字の発音の開始と終了のタイミングに焦点を当てている。歌詞のタイミング、品詞、音楽的な印象、ビート構造等からリリックアプリを構築することが出来るLyric AppFramework と比較すると、LyricBathe ははるかにシンプルなメカニズムを採用している。",
                    "list_items": [],
                    "is_enumrated": false
                },
                {
                    "content": "現在、LyricBathe には24 のモードがあり、それぞれ異なるインタラクティブモードを備えている。身体とのインタラクション、文字の大きさ、動き方などの側面に焦点を当て、24 種のモードの実装を通して、LyricBathe における歌詞表現のデザイン空間を探求している(表1)。",
                    "list_items": [],
                    "is_enumrated": false
                }
            ]
        },
        {
            "number": "4.",
            "part_name": "予備実験",
            "paragraphs_below": [
                {
                    "content": "LyricBathe のモードを用いてインタラクションプリミティブの音楽体験に与える影響について調査し、本実験で用いるモードを選定するため予備的ユーザ観察実験を行った。",
                    "list_items": [],
                    "is_enumrated": false
                }
            ]
        },
        {
            "number": "4.1",
            "part_name": "予備実験で使用した楽曲",
            "paragraphs_below": [
                {
                    "content": "予備実験を行うにあたってSuno AI [14] の歌詞生成機能を用いて歌詞を生成し、Suno AI によりその歌詞つきの楽曲を生成した。実験では、生成された楽曲から1 コーラス分のみを切り取り、曲の長さが1 分18 秒になるよう編集したものを利用した。",
                    "list_items": [],
                    "is_enumrated": false
                },
                {
                    "content": "実験結果として記録したデータでは、試行ごとに実験データの終了時刻にばらつきが見られたため、再生開始から1 分15 秒の範囲に調整して分析を行った。",
                    "list_items": [],
                    "is_enumrated": false
                }
            ]
        },
        {
            "number": "4.2",
            "part_name": "実験条件",
            "paragraphs_below": [
                {
                    "content": "大学内で参加者を募集し、20 代大学院生男性1 名を対象に実験を行った。実験環境としては、ユーザの正面方向に正方形の机を一つ配置し、それ以外の障害物を配置しない空間で実験を行った。",
                    "list_items": [],
                    "is_enumrated": false
                }
            ]
        },
        {
            "number": "4.3",
            "part_name": "実験におけるデータの計測",
            "paragraphs_below": [
                {
                    "content": "予備実験では、体験中のユーザの行動に関する2 種類のデータを、それぞれCSV ファイルとして記録した。• ユーザの注視箇所に関する時系列データ",
                    "list_items": [],
                    "is_enumrated": false
                }
            ]
        },
        {
            "number": "",
            "part_name": "• ユーザの頭部位置に関する時系列データ",
            "paragraphs_below": [
                {
                    "content": "注視箇所のデータは、HoloLens 2 のEye Tracking APIにより取得された視線情報をもとに、注視対象のタグ（詳細は次節で説明）と注視時間をCSV 形式で記録した。頭部位置のデータは、楽曲の再生開始から0.2 秒ごとに、MR空間内におけるユーザが装着しているデバイスの3 次元座標（x: 左右方向, y: 上下方向, z: 奥行き方向）を取得し、同様にCSV 形式で記録した。",
                    "list_items": [],
                    "is_enumrated": false
                }
            ]
        },
        {
            "number": "4.4",
            "part_name": "注視箇所の記録方法",
            "paragraphs_below": [
                {
                    "content": "予備実験では、Eye Tracking API により取得された視線データから、ユーザが注視している歌詞オブジェクトやその他の対象に対して、以下に示す注視タグを割り当てた。各タグをもとに、注視箇所の時系列遷移を記録し、時間の経過やインタラクションに応じて変化する注視対象の推移をデータとして取得した（図2 参照）。",
                    "list_items": [],
                    "is_enumrated": false
                },
                {
                    "content": "• CCO (Current Character Object): その時点で発声されている歌詞の文字上または表示から1 秒以内の歌詞オブジェクト上に視線がある• CPO (Current Phrase Object): その時点で発声されている歌詞の文字が入ったフレーズ上に視線がある（CCO 以外）• TLO (Touched Lyric Object): 手指で操作している歌詞の上に視線がある• OLO (Other Lyric Object): それ以外の歌詞の文字の上に視線がある（CCO でもCPO でもTLO でもないもの）• IVO (Interaction Virtual Object): 表示されているユーザインタフェースオブジェクト（シャワーキューブや矢印オブジェクト）の上に視線がある• UNO (Undefined Natural Observation): どの状態にも当てはまらない場所を注視しているCSVファイルには、注視箇所タグが切り替わるごとに注視開始と注視終了のタイムスタンプ、注視箇所のタグをそれぞれ記録した。タイムスタンプの形式はmm:ss:msの",
                    "list_items": [
                        "• CCO (Current Character Object): その時点で発声されている歌詞の文字上または表示から1 秒以内の歌詞オブジェクト上に視線がある",
                        "• CPO (Current Phrase Object): その時点で発声されている歌詞の文字が入ったフレーズ上に視線がある（CCO 以外）",
                        "• TLO (Touched Lyric Object): 手指で操作している歌詞の上に視線がある",
                        "• OLO (Other Lyric Object): それ以外の歌詞の文字の上に視線がある（CCO でもCPO でもTLO でもないもの）",
                        "• IVO (Interaction Virtual Object): 表示されているユーザインタフェースオブジェクト（シャワーキューブや矢印オブジェクト）の上に視線がある",
                        "• UNO (Undefined Natural Observation): どの状態にも当てはまらない場所を注視しているCSVファイルには、注視箇所タグが切り替わるごとに注視開始と注視終了のタイムスタンプ、注視箇所のタグをそれぞれ記録した。タイムスタンプの形式はmm:ss:msの"
                    ],
                    "is_enumrated": true
                },
                {
                    "content": "形式で文字列として記録した。",
                    "list_items": [],
                    "is_enumrated": false
                }
            ]
        },
        {
            "number": "4.5",
            "part_name": "予備実験の実施",
            "paragraphs_below": [
                {
                    "content": "予備実験では、インタラクションプリミティブによる歌詞体験の影響を調査するためLyricBathe のモード群の全24 モードを対象として実験を行った（表1）。この実験では、HoloLens 2 を装着してもらい、立った状態からLyricBathe の各モードを体験してもらった。体験中の参加者の動きに制限はかけずに実験を行った。",
                    "list_items": [],
                    "is_enumrated": false
                },
                {
                    "content": "24 種類のモードは、ランダムに並び変えて体験してもらった。モードの切り替え操作は、実験者がワイヤレスキーボードを用いて遠隔で行った。各モードで行えるインタラクションについては特に説明をせず、遠隔で楽曲の再生を開始した。",
                    "list_items": [],
                    "is_enumrated": false
                }
            ]
        },
        {
            "number": "4.6",
            "part_name": "予備実験結果に対する注視行動に基づくユーザ行動分析",
            "paragraphs_below": [
                {
                    "content": "歌詞やインタラクションに対する注視行動について分析するために視線タグのUNO は視線データから除外し、「CCO、CPO、OLO、TLO、IVO」だけの注視箇所の遷移について可視化を行った。",
                    "list_items": [],
                    "is_enumrated": false
                },
                {
                    "content": "注視箇所の遷移傾向についてK-means クラスタリングを行った結果、24 種のモードは、エルボー法により以下の4 つのクラスタに分類された.",
                    "list_items": [],
                    "is_enumrated": false
                },
                {
                    "content": "クラスタ0: M11,M18,M17,M16.M14,M13,M23,M20,M10,M21,M07,M06,M04,M03,M22,M09このクラスタのモードでは、CCO とCPO 間の遷移を基本としつつ、OLO を中心とした遷移も見られた。この結果は、現在のフレーズに注目しつつも時折周囲を確認し、歌詞を楽しむ体験が誘発されていると考えられた。",
                    "list_items": [],
                    "is_enumrated": false
                },
                {
                    "content": "クラスタ1: M05,M15,M19このクラスタのモードでは、IVO からその他の注視タグ（CCO、CPO、OLO）への遷移が多く含まれていた。この結果は、矢印型のUI オブジェクトを注視しながら操作し、歌詞オブジェクトの変化を楽しむ体験が誘発されていると考えられた。",
                    "list_items": [],
                    "is_enumrated": false
                }
            ]
        },
        {
            "number": "",
            "part_name": "クラスタ2: M08,M12",
            "paragraphs_below": [
                {
                    "content": "このクラスタのモードでは、CCO からTLO への遷移が含まれていた。この結果より、音楽と共に表示された歌詞を手で触れるようなインタラクションを誘発されていると考えられた。",
                    "list_items": [],
                    "is_enumrated": false
                }
            ]
        },
        {
            "number": "",
            "part_name": "クラスタ3: M01,M02,M24",
            "paragraphs_below": [
                {
                    "content": "このクラスタのモードでは、CCO とCPO 間の遷移がほとんどを占めていた。この結果は、フレーズの細部と全体を行き来する視線行動が誘発されていると考えられた。",
                    "list_items": [],
                    "is_enumrated": false
                }
            ]
        },
        {
            "number": "4.7",
            "part_name": "予備実験結果に対する頭部位置に基づくユーザ行動分析",
            "paragraphs_below": [
                {
                    "content": "頭部位置の評価指標として、それぞれの軸についての標準偏差と座標の範囲に着目した。頭部位置の特徴量についてのK-means クラスタリングを行った結果、24 種のモードは、エルボー法により5 つのクラスタに分類された。",
                    "list_items": [],
                    "is_enumrated": false
                },
                {
                    "content": "クラスタA: M01,M15,M08,M05,M12,M02このクラスタのモードはx 座標とz 座標の標準偏差と値の範囲が小さくなっていた。これは、あまり移動を行わず、静的に音楽鑑賞を行っていることを示していると考えられた。",
                    "list_items": [],
                    "is_enumrated": false
                },
                {
                    "content": "クラスタB: M20,M19,M18,M17,M16,M04,M14,M06,M23,M11,M03,M24このクラスタのモードは、x 座標の標準偏差と範囲が小さく、z 座標の標準偏差と範囲が大きくなっていた。これは、前後の移動を多く行いながら音楽鑑賞を行っていることを示していると考えられた。",
                    "list_items": [],
                    "is_enumrated": false
                },
                {
                    "content": "クラスタC: M10このクラスタでは、他のモードと比べてx 座標とz 座標の標準偏差と範囲が極端に大きくなっていた。これは、大幅に移動しながら音楽鑑賞を行っていることを示していると考えられた。",
                    "list_items": [],
                    "is_enumrated": false
                },
                {
                    "content": "クラスタD: M07,M21,M13このクラスタに含まれるモードは、y 座標の標準偏差と範囲が大きくなっていた。これは上下の移動が多く行われていたことを示し、床に落ちた文字にインタラクションを行っていることを示していると考えられた。",
                    "list_items": [],
                    "is_enumrated": false
                },
                {
                    "content": "クラスタE: M09,M22このクラスタのモードはクラスタC ほどではないが、x座標とz 座標の標準偏差と範囲が大きくなっていた。これは、移動しながら音楽鑑賞を行っていることを示していると考えられた。",
                    "list_items": [],
                    "is_enumrated": false
                }
            ]
        },
        {
            "number": "5.",
            "part_name": "ユーザ観察本実験",
            "paragraphs_below": [
                {
                    "content": "予備実験の分析結果を踏まえて、ユーザ行動の特徴を表すクラスタを代表するモードを8 種類選定した（図3）。モード、楽曲のジャンル、参加者の3 つの変数による歌詞体験の変化を観察するため、ユーザ観察本実験を行った。本実験では、「ある曲に適したモードがある」「モードによって誘発される体験が決まる」という仮説に基づき、LyricBatheにおける歌詞体験の構造を明らかにすることを目的として実施した。",
                    "list_items": [],
                    "is_enumrated": false
                }
            ]
        },
        {
            "number": "5.1",
            "part_name": "本実験で使用した楽曲",
            "paragraphs_below": [
                {
                    "content": "本実験を行うにあたって、SunoAI[14]を用いて日本語の歌詞の楽曲を生成した。楽曲の歌詞は、「前を向くための原動力として過去を振り返る」というプロンプトで、18フレーズからなる歌詞をChatGPTを用いて生成したものを利用した。Suno AI を用いて同一の歌詞を用いてジャンルの異なる3 つの楽曲を生成した。生成する楽曲ジャンルとして楽曲のテンポ感に着目し、バラード（BPM: 90）、ヒップホップ(BPM: 110)、ロック(BPM: 160) の3 種類のジャンルの楽曲を生成した。実験では、生成した楽曲から1 コーラス分を切り取り、曲の長さが47 秒になるように編集したものを使用した。分析にあたっては、実験で記録したデータのうち再生開始から45 秒の範囲を使用した。",
                    "list_items": [],
                    "is_enumrated": false
                }
            ]
        },
        {
            "number": "5.2",
            "part_name": "実験手順",
            "paragraphs_below": [
                {
                    "content": "実験参加者は、大学生の男性3 名と、大学教員の女性1名の計4 名である。実験環境として日常生活における壁や机などの周囲環境を想定し、左右に仕切りと机がある環境で実験を行った。実験環境に基準点を設定し、実験では参加者に1 試行ごとに基準となる位置に戻ってもらい、LyricBathe を体験してもらった。",
                    "list_items": [],
                    "is_enumrated": false
                },
                {
                    "content": "本実験では、M01、M03、M07、M08、M09、M10、M14、M15 の8 モード（図3）において、歌詞が同一でジャンルの異なる3 楽曲を用いたユーザ観察実験を行った。参加者にはHoloLens 2 を装着してもらい、視線追跡のキャリブレーションを行った後、基準点に立った状態でLyricBatheを起動してもらい、各モードを体験してもらった。",
                    "list_items": [],
                    "is_enumrated": false
                },
                {
                    "content": "モードの体験順は全参加者で統一し、M01、M03、M07、M08、M09、M10、M14、M15 の順で実施した。各モードにおける3 楽曲の体験順は参加者ごとにランダムに設定し、計24 試行（8 モード× 3 楽曲）を行った。モードおよび楽曲の切り替えは、実験者がワイヤレスキーボードを用いて遠隔で操作した。モードの切り替えごとに、そのモードで可能なインタラクションについて簡単な説明を行い、その後楽曲を再生した。",
                    "list_items": [],
                    "is_enumrated": false
                },
                {
                    "content": "また、予備実験と同様に、ユーザの見ている映像データ、体験中の注視箇所と頭部位置に関する2 つのCSV ファイルを記録した。",
                    "list_items": [],
                    "is_enumrated": false
                },
                {
                    "content": "各参加者には、LyricBathe の体験終了後、以下の質問を含む半構造化インタビューを実施した。",
                    "list_items": [],
                    "is_enumrated": false
                },
                {
                    "content": "• 印象に残ったモードはどのモードか• いまいちだと感じたモードがあったか• モードによって取りたくなった行動があるか• 楽曲ごとにマッチしたモードがあったか",
                    "list_items": [
                        "• 印象に残ったモードはどのモードか",
                        "• いまいちだと感じたモードがあったか",
                        "• モードによって取りたくなった行動があるか",
                        "• 楽曲ごとにマッチしたモードがあったか"
                    ],
                    "is_enumrated": true
                }
            ]
        },
        {
            "number": "6.",
            "part_name": "本実験の結果と分析",
            "paragraphs_below": [
                {
                    "content": "本節では、実験データの分析結果を示す。なお、以下では各要素を以下のように表記する：Mxx はモードのID（M01、M03、M07、M08、M09、M10、M14、M15）、Sxxは楽曲のID（S01：ロック調、S02：ヒップホップ調、S03：バラード調）、Pxx は参加者のID（P01、P02、P03、P04）を表す。",
                    "list_items": [],
                    "is_enumrated": false
                }
            ]
        },
        {
            "number": "6.1",
            "part_name": "インタビュー結果",
            "paragraphs_below": [
                {
                    "content": "各参加者のインタビュー結果を表2 に示す。",
                    "list_items": [],
                    "is_enumrated": false
                }
            ]
        },
        {
            "number": "6.2",
            "part_name": "注視割合による体験スタイルの多様性の抽出",
            "paragraphs_below": [
                {
                    "content": "LyricBatheにおける視線行動の特徴を把握するため、まず注視箇所（ラベル：CCO,CPO,OLO,TLO,IVO）ごとの注視時間割合を分析した。この分析の目的は、同じモードでも参加者ごとに視線行動が異なるのか、あるいはモードが視線行動を一様に誘発するのかを明らかにすることである。",
                    "list_items": [],
                    "is_enumrated": false
                },
                {
                    "content": "具体的には、(参加者ID× モードID× 楽曲ID)ごとの注視割合ベクトルを抽出し、モードと楽曲の組み合わせごとに4名の参加者間でのばらつきを計算した。ばらつきの指標としては、各注視ラベルの割合の標準偏差を用いた。図4には、モードと楽曲ごとの参加者別の注視箇所の割合を棒グラフで表したものである。ここからは、M01では、CCO/CPO への注視割合が高く、全員の注視が発声中の歌詞に集中していることがわかる。M08 は全参加者でIVO の割合が多く、ユーザインタフェースオブジェクトへ注視が集中していることがわかる。一方で、M03 やM09 では注視割合の構成が参加者によって異なり、OLOやTLO への注視が多い参加者もいれば、CCO/CPO への集中が見られる参加者も見られた。",
                    "list_items": [],
                    "is_enumrated": false
                },
                {
                    "content": "これらの差異を定量的に示したのが図5 である。図5 では、縦軸の値として各モードにおける注視割合の参加者間の違いに関するユークリッド距離を示している。この結果から、M01, M08 のようなモードでは参加者間の差が小さく、視線行動が設計によって強く統制されていることがわかる。一方、M03, M07 などは高いばらつきを示し、ユーザの選好に応じた視線行動が現れていることが見て取れた。",
                    "list_items": [],
                    "is_enumrated": false
                },
                {
                    "content": "この分析により、モードによって視線行動の自由度に違いがあり、それが体験の多様性に直結していることが示された。",
                    "list_items": [],
                    "is_enumrated": false
                }
            ]
        },
        {
            "number": "6.3",
            "part_name": "頭部位置データに基づく空間探索行動の分析",
            "paragraphs_below": [
                {
                    "content": "視線に加え、身体の動きによる空間的探索行動を明らかにするため、各試行における頭部位置データを分析した。目的は、ユーザがどの程度空間的に移動しながら体験していたかを定量化し、視線と同様にモードや楽曲の影響が現れるかを検証することである。分析方法としては、x, y, z座標の標準偏差と範囲（最大－最小）をそれぞれ算出し、以下の式によって「空間探索スコア」を定義した。",
                    "list_items": [],
                    "is_enumrated": false
                },
                {
                    "content": "[y][ran][g][e][ +][ z][ran][g][e]空間探索スコア=[x][ran][g][e][ +](1)xstd + ystd + zstdこのスコアは、ユーザがその場で揺れるように動いていた場合は低くなり、逆に目的をもって移動していた場合は高くなると解釈できる。",
                    "list_items": [],
                    "is_enumrated": false
                },
                {
                    "content": "表3 の参加者間のモード×楽曲ごとの6 次元ベクトル（各軸の標準偏差と範囲）のユークリッド距離を見ても、モード間や楽曲間を横断する傾向は見られなかった。このことから、頭部位置データは視線ほどモードや楽曲の設計効果を反映せず、個人の探索スタイルや姿勢のクセが強く現れることが示唆された。すなわち、視線は「モードに応じた体験」を捉える指標として有効である一方、頭部の動きは「人の特性」を映し出す傾向が強いという結論に至った。",
                    "list_items": [],
                    "is_enumrated": false
                }
            ]
        },
        {
            "number": "6.4",
            "part_name": "主観的評価との整合性の検証",
            "paragraphs_below": [
                {
                    "content": "定性的なインタビューから得られたユーザの主観的評価と、視線データの定量的特徴がどのように一致しているかを検討した。目的は、視線分析の信頼性と意味解釈の妥当性を高めることである。",
                    "list_items": [],
                    "is_enumrated": false
                },
                {
                    "content": "参加者ごとにインタビュー記述から重視している体験の軸を抽出し、それが注視割合や遷移パターンと一致しているかを検証した。図7 には、各参加者の代表的な発話内容と注視遷移ヒートマップを対応づけて示している。",
                    "list_items": [],
                    "is_enumrated": false
                },
                {
                    "content": "P01 は「歌詞を裏から見る」「残された歌詞がウッとくる」といった発言をしており、OLO への注視が多く、OLOとCPO の間の遷移も頻繁であった。P02 は「今流れている歌詞に集中したい」「揺らめきがよかった」と語り、CCOとCPO の注視割合が高く、遷移も非常に少なかった。P03は「歌詞をつまんだりして触った」「座り込んで見ていた」など操作性に言及しており、OLO とIVO への注視が多かった。P04 は構造的変化（落下・積み上げ・破壊）に関心を示し、OLO およびTLO の注視と、広がった遷移構造が対応していた。",
                    "list_items": [],
                    "is_enumrated": false
                },
                {
                    "content": "このように、主観的記述と視線データが整合している事例が多数確認され、視線行動に基づいた体験スタイル分析の妥当性が支持された。",
                    "list_items": [],
                    "is_enumrated": false
                }
            ]
        },
        {
            "number": "6.5",
            "part_name": "PCA に基づくモード誘発性と個人差の関係",
            "paragraphs_below": [
                {
                    "content": "体験スタイルが参加者とモードのどちらにより影響されるかを明らかにするため、注視割合ベクトルをPCA により次元圧縮し、クラスタリングを行った。目的は、視線スタイルが参加者に固有のものであるのか、モードによって一貫して誘発されるのかを可視化することである。",
                    "list_items": [],
                    "is_enumrated": false
                },
                {
                    "content": "図8は、各試行のPCAプロットにクラスタラベルを付与したものである。これを見ると、M01,M08,M07ではすべての参加者が同一クラスタに属しており、これらのモードでは視線スタイルがモードによって一貫して誘導されていることが示された。一方、M03やM09などでは参加者が異なるクラスタに分散しており、モード内での視線行動が個人によって異なっていた。このように、モードごとに視線行動の誘発力に違いがあり、個人の重視する体験スタイルが表出しやすいモードと、モード設計によって体験が固定化されるモードが存在することがわかった。",
                    "list_items": [],
                    "is_enumrated": false
                }
            ]
        },
        {
            "number": "6.6",
            "part_name": "楽曲と体験スタイルの関係性の分析",
            "paragraphs_below": [
                {
                    "content": "最後に、楽曲の曲調が視線行動にどのように影響を与えているかを検討した。分析は2 つの観点から行われた。第一に、モードごとの「曲調に対する感受性」を測定するため、同一モードにおける3 楽曲（S01, S02, S03）の視線遷移行列のベクトルの分散合計（total variance）を算出した。図9 にその結果を示す。",
                    "list_items": [],
                    "is_enumrated": false
                },
                {
                    "content": "M03 は特にtotal variance が高く、曲調によって体験スタイルが切り替わりやすいモードであることが確認された。一方、M01 はどの曲調においても遷移構造が安定しており、曲調の違いによる視線行動の変化がほとんど見られなかった。",
                    "list_items": [],
                    "is_enumrated": false
                },
                {
                    "content": "第二に、各曲調と体験スタイルの相性について、インタビューと視線スコアを用いて整理した(図10)。S01（ロック）はCCO/CPO への集中が高く、没入型の体験と親和性が見られた。S02（ヒップホップ）はTLO/OLO が多く、操作的・探索的な体験が促されていた。S03（バラード）は視線の分布が比較的バランスしており、複合型の体験が誘発されやすいことが示唆された。このように、モードだけでなく曲調も体験スタイルに影響を与える要因であることが明らかになった。モードのデザインと曲調の特性が互いに作用し合い、ユーザの体験を構成していることが、本研究からの重要な知見のひとつである。",
                    "list_items": [],
                    "is_enumrated": false
                }
            ]
        },
        {
            "number": "7.",
            "part_name": "結論",
            "paragraphs_below": [
                {
                    "content": "本研究では、Mixed Reality 環境における視線と身体行動のデータを用いて、LyricBathe における歌詞体験の構造を明らかにした。分析の出発点として、「ある曲に適したモードがある」「モードによって誘発される体験が決まる」という2 つの仮説を設定し、視線注視割合、注視遷移構造、頭部位置変化、インタビュー評価を総合的に分析した。注視割合の分析からは、モードによって視線行動が強く規定される場合と、個人差が顕著に現れる場合があることが明らかとなった。これは、モードの設計がユーザ体験における「誘発性」として機能していることを示している。また、頭部位置データの分析では、モードや曲調による影響は限定的であり、個人の身体的傾向がより強く反映されることが確認された。さらに、インタビュー結果と視線行動を照合したことで、主観的な体験評価と客観的な視線データが高い一致を示すことがわかった。これは、視線データに基づく体験スタイルの定量分析が、ユーザの主観的印象と対応していることを支持する。PCA とクラスタリングに基づく分析では、モードによって視線行動が収束する場合と、個人差がそのまま現れる場合が構造的に区別できた。また、楽曲の曲調によって体験スタイルが変化するモードも確認され、モードと曲調の組み合わせによって適切な体験が誘発されるという本研究の仮説を支持する結果が得られた。",
                    "list_items": [],
                    "is_enumrated": false
                },
                {
                    "content": "これらの結果から、モードの設計は単に視覚的な演出にとどまらず、ユーザの体験スタイルそのものを形成する要素であることが明らかとなった。また、楽曲のテンポや構造といった属性に応じて最適なモードを推薦する適応的システム設計への展開可能性が示された。本研究は、視線行動の定量分析を用いてMR 環境における複雑なユーザ体験の構造を可視化する手がかりを提示するものであり、今後の体験設計における基盤的知見となると考えられる。",
                    "list_items": [],
                    "is_enumrated": false
                },
                {
                    "content": "謝辞本研究の一部は、JST、ACT-X、JPMJAX22A3の支援を受けたものである。LyricBathe を体験し多くの貴重なフィードバックを下さった方々に深く感謝する。",
                    "list_items": [],
                    "is_enumrated": false
                }
            ]
        }
    ],
    "figures": [
        {
            "stringize_content": "図1LyricBathe 体験中のユーザの様子",
            "number": 1,
            "title": "LyricBathe 体験中のユーザの様子",
            "etitle": null
        },
        {
            "stringize_content": "図2注視箇所タグごとの代表例",
            "number": 2,
            "title": "注視箇所タグごとの代表例",
            "etitle": null
        },
        {
            "stringize_content": "",
            "number": 3,
            "title": "本実験で用いたLyricBathe の8 種のモード",
            "etitle": null
        },
        {
            "stringize_content": "",
            "number": 4,
            "title": "参加者ごとのモードと楽曲の組み合わせにおける注視タグごとの注視割合",
            "etitle": null
        },
        {
            "stringize_content": "",
            "number": 5,
            "title": "各モードにおける注視割合の参加者間の違いに関するユークリッド距離",
            "etitle": null
        },
        {
            "stringize_content": "図6参加者ごとの各モードの探索スコア（楽曲平均）",
            "number": 6,
            "title": "は、各参加者のモードごとの空間探索スコアをプロットしたものである。図から、P01 は全体的にスコアが低く、あまり移動していなかったことが読み取れる。一方、P02 は全体的にスコアが高く、特にM09～M14 において積極的に空間を移動していたことが読み取れる。P03やP04 は一部のモードでスコアが高かったが、モードごとのばらつきが見られた。これらの結果から、空間探索行動はモードや楽曲に応じた変化よりも、個人差の方が顕著であることが確認された。",
            "etitle": null
        },
        {
            "stringize_content": "",
            "number": 7,
            "title": "各参加者のインタビュー内容と注視遷移のヒートマップ",
            "etitle": null
        },
        {
            "stringize_content": "",
            "number": 8,
            "title": "参加者ごとの各モードにおける注視遷移のPCAプロット",
            "etitle": null
        },
        {
            "stringize_content": "",
            "number": 9,
            "title": "モードごとのtotal variance に関する棒グラフ",
            "etitle": null
        },
        {
            "stringize_content": "",
            "number": 10,
            "title": "楽曲ごとの平均注視遷移率に関するヒートマップ",
            "etitle": null
        }
    ],
    "tables": [
        {
            "cells": [
                [
                    "",
                    "表1\nLyricBathe で実装した24 種類のモードとそれを構成するインタラクションプリミティブ",
                    null,
                    null,
                    null,
                    null,
                    null,
                    null,
                    null,
                    null,
                    null,
                    null
                ],
                [
                    "Interaction \nPrimitives",
                    "1",
                    "2",
                    "3",
                    "4",
                    "5",
                    "6",
                    "7",
                    "8",
                    "9",
                    "10",
                    "11"
                ],
                [
                    "",
                    "How to \nArrange \nCharacters",
                    "Where to \nDisplay  \nCharacters",
                    "Scaling \nCharacters",
                    "When to \nDisplay \nCharacters",
                    "How Long to \nKeep Displaying \nCharacters",
                    "Units for \nDefning  \nBehavior",
                    "Character \nMovement",
                    "Phrase \nMoveme\nnt",
                    "User \nInteraction",
                    "Whether \nvirtual objects \nhave physical \nproperties",
                    "When to \nApply \nPhysical \nProperties"
                ],
                [
                    "modes",
                    "",
                    "",
                    "",
                    "",
                    "",
                    "",
                    "",
                    "",
                    "",
                    "",
                    ""
                ],
                [
                    "M01",
                    "straight line",
                    "relative \npositioning",
                    "1x",
                    "character-\nbased",
                    "disappeared at the \nend of each \nphrase",
                    "phrase",
                    "n/a",
                    "fowing \nout from \nbody",
                    "fnger-based \ngestures",
                    "No",
                    "n/a"
                ],
                [
                    "M02",
                    "straight line",
                    "relative \npositioning",
                    "1x",
                    "character-\nbased",
                    "disappeared at the \nend of each \nphrase",
                    "phrase",
                    "n/a",
                    "fowing \nbetween \nfngers",
                    "fnger-based \ngestures",
                    "No",
                    "n/a"
                ],
                [
                    "M03",
                    "straight line",
                    "absolute \npositioning",
                    "1x",
                    "character-\nbased",
                    "25 seconds after \nthe end of the \nphrase",
                    "character",
                    "falling",
                    "n/a",
                    "palm-based \ngestures",
                    "Yes",
                    "at the end \nof each \nphrase"
                ],
                [
                    "M04",
                    "straight line",
                    "absolute \npositioning",
                    "1x",
                    "character-\nbased",
                    "25 seconds after \nthe end of the \nphrase",
                    "character",
                    "foating",
                    "n/a",
                    "palm-based \ngestures",
                    "Yes",
                    "at the end \nof each \nphrase"
                ],
                [
                    "M05",
                    "straight line",
                    "absolute \npositioning",
                    "1x",
                    "character-\nbased",
                    "25 seconds after \nthe end of the \nphrase",
                    "character",
                    "directing",
                    "n/a",
                    "palm-based \ngestures",
                    "Yes",
                    "at the end \nof each \nphrase"
                ],
                [
                    "M06",
                    "straight line",
                    "absolute \npositioning",
                    "1x",
                    "character-\nbased",
                    "25 seconds after \nthe end of the \nphrase",
                    "character",
                    "Throwing \naway",
                    "n/a",
                    "fnger-based \ngestures \npalm-based \ngestures",
                    "Yes",
                    "at the end \nof each \nphrase"
                ],
                [
                    "M07",
                    "straight line",
                    "absolute \npositioning",
                    "1x",
                    "song-\nbased",
                    "25 seconds after \nthe end of the \nphrase",
                    "character",
                    "gathering \nto phrase",
                    "n/a",
                    "palm-based \ngestures",
                    "Yes",
                    "when each \ncharacter \nappears"
                ],
                [
                    "M08",
                    "straight line",
                    "relative \npositioning",
                    "1x",
                    "character-\nbased",
                    "25 seconds after \nthe end of the \nphrase",
                    "character",
                    "shower",
                    "n/a",
                    "palm-based \ngestures",
                    "Yes",
                    "at the end \nof each \nphrase"
                ],
                [
                    "M09",
                    "straight line",
                    "absolute \npositioning",
                    "5x",
                    "character-\nbased",
                    "25 seconds after \nthe end of the \nphrase",
                    "character",
                    "falling",
                    "n/a",
                    "palm-based \ngestures",
                    "Yes",
                    "at the end \nof each \nphrase"
                ],
                [
                    "M10",
                    "straight line",
                    "absolute \npositioning",
                    "15x",
                    "character-\nbased",
                    "25 seconds after \nthe end of the \nphrase",
                    "character",
                    "falling",
                    "n/a",
                    "palm-based \ngestures",
                    "Yes",
                    "at the end \nof each \nphrase"
                ],
                [
                    "M11",
                    "straight line",
                    "absolute \npositioning",
                    "1x",
                    "song-\nbased",
                    "25 seconds after \nthe end of the \nphrase",
                    "character",
                    "gathering \nto phrase",
                    "n/a",
                    "palm-based \ngestures",
                    "Yes",
                    "when each \ncharacter \nappears"
                ],
                [
                    "M12",
                    "straight line",
                    "relative \npositioning",
                    "1x",
                    "character-\nbased",
                    "25 seconds after \nthe end of the \nphrase",
                    "character",
                    "falling",
                    "n/a",
                    "palm-based \ngestures",
                    "Yes",
                    "when each \ncharacter \nappears"
                ],
                [
                    "M13",
                    "straight line",
                    "absolute \npositioning",
                    "1x",
                    "character-\nbased",
                    "25 seconds after \nthe end of the \nphrase",
                    "phrase",
                    "n/a",
                    "falling",
                    "palm-based \ngestures",
                    "Yes",
                    "at the end \nof each \nphrase"
                ],
                [
                    "M14",
                    "straight line",
                    "absolute \npositioning",
                    "1x",
                    "character-\nbased",
                    "25 seconds after \nthe end of the \nphrase",
                    "phrase",
                    "n/a",
                    "foating",
                    "palm-based \ngestures",
                    "Yes",
                    "at the end \nof each \nphrase"
                ],
                [
                    "M15",
                    "straight line",
                    "absolute \npositioning",
                    "1x",
                    "character-\nbased",
                    "25 seconds after \nthe end of the \nphrase",
                    "phrase",
                    "n/a",
                    "directing",
                    "palm-based \ngestures",
                    "Yes",
                    "at the end \nof each \nphrase"
                ],
                [
                    "M16",
                    "straight line",
                    "absolute \npositioning",
                    "1x",
                    "character-\nbased",
                    "25 seconds after \nthe end of the \nphrase",
                    "phrase",
                    "n/a",
                    "throwing \naway",
                    "fnger-based \ngestures \npalm-based \ngestures",
                    "Yes",
                    "at the end \nof each \nphrase"
                ],
                [
                    "M17",
                    "straight line",
                    "absolute \npositioning",
                    "1x",
                    "phrase-\nbased",
                    "25 seconds after \nthe end of the \nphrase",
                    "character",
                    "falling",
                    "n/a",
                    "palm-based \ngestures",
                    "Yes",
                    "at the end \nof each \nphrase"
                ],
                [
                    "M18",
                    "straight line",
                    "absolute \npositioning",
                    "1x",
                    "phrase-\nbased",
                    "25 seconds after \nthe end of the \nphrase",
                    "character",
                    "foating",
                    "n/a",
                    "palm-based \ngestures",
                    "Yes",
                    "at the end \nof each \nphrase"
                ],
                [
                    "M19",
                    "straight line",
                    "absolute \npositioning",
                    "1x",
                    "phrase-\nbased",
                    "25 seconds after \nthe end of the \nphrase",
                    "character",
                    "directing",
                    "n/a",
                    "palm-based \ngestures",
                    "Yes",
                    "at the end \nof each \nphrase"
                ],
                [
                    "M20",
                    "straight line",
                    "absolute \npositioning",
                    "1x",
                    "phrase-\nbased",
                    "25 seconds after \nthe end of the \nphrase",
                    "character",
                    "Throwing \naway",
                    "n/a",
                    "fnger-based \ngestures \npalm-based \ngestures",
                    "Yes",
                    "at the end \nof each \nphrase"
                ],
                [
                    "M21",
                    "circular \nshape",
                    "absolute \npositioning",
                    "1x",
                    "character-\nbased",
                    "25 seconds after \nthe end of the \nphrase",
                    "character",
                    "falling",
                    "n/a",
                    "palm-based \ngestures",
                    "Yes",
                    "at the end \nof each \nphrase"
                ],
                [
                    "M22",
                    "random",
                    "absolute \npositioning",
                    "random \nscaling",
                    "character-\nbased",
                    "25 seconds after \nthe end of the \nphrase",
                    "character",
                    "falling",
                    "n/a",
                    "palm-based \ngestures",
                    "Yes",
                    "at the end \nof each \nphrase"
                ],
                [
                    "M23",
                    "fnger \ntracking",
                    "absolute \npositioning",
                    "1x",
                    "character-\nbased",
                    "25 seconds after \nthe end of the \nphrase",
                    "character",
                    "falling",
                    "n/a",
                    "fnger-based \ngestures \npalm-based \ngestures",
                    "Yes",
                    "at the end \nof each \nphrase"
                ],
                [
                    "M24",
                    "fnger \ntracking",
                    "absolute \npositioning \nrelative \npositioning",
                    "1x",
                    "character-\nbased",
                    "25 seconds after \nthe end of the \nphrase",
                    "character",
                    "falling",
                    "n/a",
                    "fnger-based \ngestures \npalm-based \ngestures",
                    "Yes",
                    "at the end \nof each \nphrase"
                ]
            ],
            "content": "||表**1**<br>LyricBatheで実装した24 種類のモードとそれを構成するインタラクションプリミティブ|表**1**<br>LyricBatheで実装した24 種類のモードとそれを構成するインタラクションプリミティブ|表**1**<br>LyricBatheで実装した24 種類のモードとそれを構成するインタラクションプリミティブ|表**1**<br>LyricBatheで実装した24 種類のモードとそれを構成するインタラクションプリミティブ|表**1**<br>LyricBatheで実装した24 種類のモードとそれを構成するインタラクションプリミティブ|表**1**<br>LyricBatheで実装した24 種類のモードとそれを構成するインタラクションプリミティブ|表**1**<br>LyricBatheで実装した24 種類のモードとそれを構成するインタラクションプリミティブ|表**1**<br>LyricBatheで実装した24 種類のモードとそれを構成するインタラクションプリミティブ|表**1**<br>LyricBatheで実装した24 種類のモードとそれを構成するインタラクションプリミティブ|表**1**<br>LyricBatheで実装した24 種類のモードとそれを構成するインタラクションプリミティブ|表**1**<br>LyricBatheで実装した24 種類のモードとそれを構成するインタラクションプリミティブ|\n|---|---|---|---|---|---|---|---|---|---|---|---|\n|**Interaction**<br>**Primitives**|<br> <br>**1**|**2**|**3**|**4**|**5**|**6**|**7**|**8**|**9**|**10**|**11**|\n||**How to**<br>**Arrange**<br>**Characters**|**Where to**<br>**Display**<br>**Characters**|**Scaling**<br>**Characters**|**When to**<br>**Display**<br>**Characters**|**How Long to**<br>**Keep Displaying**<br>**Characters**|**Units for**<br>**Defning**<br>**Behavior**|**Character**<br>**Movement**|**Phrase**<br>**Moveme**<br>**nt**|**User**<br>**Interaction**|**Whether**<br>**virtual objects**<br>**have physical**<br>**properties**|**When to**<br>**Apply**<br>**Physical**<br>**Properties**|\n|**modes**||||||||||||\n|**M01**|straight line|relative<br>positioning|1x|character-<br>based|disappeared at the<br>end of each<br>phrase|phrase|n/a|fowing<br>out from<br>body|fnger-based<br>gestures|No|n/a|\n|**M02**|straight line|relative<br>positioning|1x|character-<br>based|disappeared at the<br>end of each<br>phrase|phrase|n/a|fowing<br>between<br>fngers|fnger-based<br>gestures|No|n/a|\n|**M03**|straight line|absolute<br>positioning|1x|character-<br>based|25 seconds after<br>the end of the<br>phrase|character|falling|n/a|palm-based<br>gestures|Yes|at the end<br>of each<br>phrase|\n|**M04**|straight line|absolute<br>positioning|1x|character-<br>based|25 seconds after<br>the end of the<br>phrase|character|foating|n/a|palm-based<br>gestures|Yes|at the end<br>of each<br>phrase|\n|**M05**|straight line|absolute<br>positioning|1x|character-<br>based|25 seconds after<br>the end of the<br>phrase|character|directing|n/a|palm-based<br>gestures|Yes|at the end<br>of each<br>phrase|\n|**M06**|straight line|absolute<br>positioning|1x|character-<br>based|25 seconds after<br>the end of the<br>phrase|character|Throwing<br>away|n/a|fnger-based<br>gestures<br>palm-based<br>gestures|Yes|at the end<br>of each<br>phrase|\n|**M07**|straight line|absolute<br>positioning|1x|song-<br>based|25 seconds after<br>the end of the<br>phrase|character|gathering<br>to phrase|n/a|palm-based<br>gestures|Yes|when each<br>character<br>appears|\n|**M08**|straight line|relative<br>positioning|1x|character-<br>based|25 seconds after<br>the end of the<br>phrase|character|shower|n/a|palm-based<br>gestures|Yes|at the end<br>of each<br>phrase|\n|**M09**|straight line|absolute<br>positioning|5x|character-<br>based|25 seconds after<br>the end of the<br>phrase|character|falling|n/a|palm-based<br>gestures|Yes|at the end<br>of each<br>phrase|\n|**M10**|straight line|absolute<br>positioning|15x|character-<br>based|25 seconds after<br>the end of the<br>phrase|character|falling|n/a|palm-based<br>gestures|Yes|at the end<br>of each<br>phrase|\n|**M11**|straight line|absolute<br>positioning|1x|song-<br>based|25 seconds after<br>the end of the<br>phrase|character|gathering<br>to phrase|n/a|palm-based<br>gestures|Yes|when each<br>character<br>appears|\n|**M12**|straight line|relative<br>positioning|1x|character-<br>based|25 seconds after<br>the end of the<br>phrase|character|falling|n/a|palm-based<br>gestures|Yes|when each<br>character<br>appears|\n|**M13**|straight line|absolute<br>positioning|1x|character-<br>based|25 seconds after<br>the end of the<br>phrase|phrase|n/a|falling|palm-based<br>gestures|Yes|at the end<br>of each<br>phrase|\n|**M14**|straight line|absolute<br>positioning|1x|character-<br>based|25 seconds after<br>the end of the<br>phrase|phrase|n/a|foating|palm-based<br>gestures|Yes|at the end<br>of each<br>phrase|\n|**M15**|straight line|absolute<br>positioning|1x|character-<br>based|25 seconds after<br>the end of the<br>phrase|phrase|n/a|directing|palm-based<br>gestures|Yes|at the end<br>of each<br>phrase|\n|**M16**|straight line|absolute<br>positioning|1x|character-<br>based|25 seconds after<br>the end of the<br>phrase|phrase|n/a|throwing<br>away|fnger-based<br>gestures<br>palm-based<br>gestures|Yes|at the end<br>of each<br>phrase|\n|**M17**|straight line|absolute<br>positioning|1x|phrase-<br>based|25 seconds after<br>the end of the<br>phrase|character|falling|n/a|palm-based<br>gestures|Yes|at the end<br>of each<br>phrase|\n|**M18**|straight line|absolute<br>positioning|1x|phrase-<br>based|25 seconds after<br>the end of the<br>phrase|character|foating|n/a|palm-based<br>gestures|Yes|at the end<br>of each<br>phrase|\n|**M19**|straight line|absolute<br>positioning|1x|phrase-<br>based|25 seconds after<br>the end of the<br>phrase|character|directing|n/a|palm-based<br>gestures|Yes|at the end<br>of each<br>phrase|\n|**M20**|straight line|absolute<br>positioning|1x|phrase-<br>based|25 seconds after<br>the end of the<br>phrase|character|Throwing<br>away|n/a|fnger-based<br>gestures<br>palm-based<br>gestures|Yes|at the end<br>of each<br>phrase|\n|**M21**|circular<br>shape|absolute<br>positioning|1x|character-<br>based|25 seconds after<br>the end of the<br>phrase|character|falling|n/a|palm-based<br>gestures|Yes|at the end<br>of each<br>phrase|\n|**M22**|random|absolute<br>positioning|random<br>scaling|character-<br>based|25 seconds after<br>the end of the<br>phrase|character|falling|n/a|palm-based<br>gestures|Yes|at the end<br>of each<br>phrase|\n|**M23**|fnger<br>tracking|absolute<br>positioning|1x|character-<br>based|25 seconds after<br>the end of the<br>phrase|character|falling|n/a|fnger-based<br>gestures<br>palm-based<br>gestures|Yes|at the end<br>of each<br>phrase|\n|**M24**|fnger<br>tracking|absolute<br>positioning<br>relative<br>positioning|1x|character-<br>based|25 seconds after<br>the end of the<br>phrase|character|falling|n/a|fnger-based<br>gestures<br>palm-based<br>gestures|Yes|at the end<br>of each<br>phrase|\n\n",
            "number": 1,
            "title": "LyricBatheで実装した24 種類のモードとそれを構成するインタラクションプリミティブ表1LyricBatheで実装した24 種類のモードとそれを構成するインタラクションプリミティブ表1LyricBatheで実装した24 種類のモードとそれを構成するインタラクションプリミティブ表1LyricBatheで実装した24 種類のモードとそれを構成するインタラクションプリミティブ表1LyricBatheで実装した24 種類のモードとそれを構成するインタラクションプリミティブ表1LyricBatheで実装した24 種類のモードとそれを構成するインタラクションプリミティブ表1LyricBatheで実装した24 種類のモードとそれを構成するインタラクションプリミティブ表1LyricBatheで実装した24 種類のモードとそれを構成するインタラクションプリミティブ表1LyricBatheで実装した24 種類のモードとそれを構成するインタラクションプリミティブ表1LyricBatheで実装した24 種類のモードとそれを構成するインタラクションプリミティブ表1LyricBatheで実装した24 種類のモードとそれを構成するインタラクションプリミティブ",
            "etitle": ""
        },
        {
            "cells": [
                [
                    "表2各参加者へのインタビュー結果"
                ]
            ],
            "content": "表2各参加者へのインタビュー結果",
            "number": 2,
            "title": "各参加者へのインタビュー結果",
            "etitle": null
        },
        {
            "cells": [
                [
                    "（",
                    "昇順でソート）",
                    null,
                    null
                ],
                [
                    null,
                    "mode",
                    "song",
                    "avg_6D_euclidean_distance"
                ],
                [
                    null,
                    "M15",
                    "S02",
                    "0.49"
                ],
                [
                    null,
                    "M09",
                    "S01",
                    "0.57"
                ],
                [
                    null,
                    "M08",
                    "S01",
                    "0.59"
                ],
                [
                    null,
                    "M15",
                    "S03",
                    "0.60"
                ],
                [
                    null,
                    "M10",
                    "S01",
                    "0.60"
                ],
                [
                    null,
                    "M01",
                    "S02",
                    "0.60"
                ],
                [
                    null,
                    "M09",
                    "S03",
                    "0.71"
                ],
                [
                    null,
                    "M10",
                    "S02",
                    "0.75"
                ],
                [
                    null,
                    "M03",
                    "S02",
                    "0.77"
                ],
                [
                    null,
                    "M01",
                    "S03",
                    "0.78"
                ],
                [
                    null,
                    "M07",
                    "S01",
                    "0.80"
                ],
                [
                    null,
                    "M10",
                    "S03",
                    "0.86"
                ],
                [
                    null,
                    "M08",
                    "S02",
                    "0.93"
                ],
                [
                    null,
                    "M03",
                    "S01",
                    "0.99"
                ],
                [
                    null,
                    "M09",
                    "S02",
                    "1.01"
                ],
                [
                    null,
                    "M03",
                    "S03",
                    "1.02"
                ],
                [
                    null,
                    "M07",
                    "S02",
                    "1.07"
                ],
                [
                    null,
                    "M01",
                    "S01",
                    "1.08"
                ],
                [
                    null,
                    "M15",
                    "S01",
                    "1.19"
                ],
                [
                    null,
                    "M14",
                    "S01",
                    "1.26"
                ],
                [
                    null,
                    "M08",
                    "S03",
                    "1.26"
                ],
                [
                    null,
                    "M14",
                    "S02",
                    "1.32"
                ],
                [
                    null,
                    "M14",
                    "S03",
                    "1.33"
                ],
                [
                    null,
                    "M07",
                    "S03",
                    "1.34"
                ]
            ],
            "content": "|（|昇順でソート）|昇順でソート）|昇順でソート）|\n|---|---|---|---|\n||**mode**|**song**|**avg_6D_euclidean_distance**|\n||**M15**|**S02**|**0.49**|\n||**M09**|**S01**|**0.57**|\n||**M08**|**S01**|**0.59**|\n||**M15**|**S03**|**0.60**|\n||**M10**|**S01**|**0.60**|\n||**M01**|**S02**|**0.60**|\n||**M09**|**S03**|**0.71**|\n||**M10**|**S02**|**0.75**|\n||**M03**|**S02**|**0.77**|\n||**M01**|**S03**|**0.78**|\n||**M07**|**S01**|**0.80**|\n||**M10**|**S03**|**0.86**|\n||**M08**|**S02**|**0.93**|\n||**M03**|**S01**|**0.99**|\n||**M09**|**S02**|**1.01**|\n||**M03**|**S03**|**1.02**|\n||**M07**|**S02**|**1.07**|\n||**M01**|**S01**|**1.08**|\n||**M15**|**S01**|**1.19**|\n||**M14**|**S01**|**1.26**|\n||**M08**|**S03**|**1.26**|\n||**M14**|**S02**|**1.32**|\n||**M14**|**S03**|**1.33**|\n||**M07**|**S03**|**1.34**|\n\n",
            "number": 3,
            "title": "頭部位置の動きによるモードと楽曲ごとのユークリッド距離",
            "etitle": ""
        }
    ],
    "footnotes": [
        {
            "sign": "1",
            "content": "公立はこだて未来大学2産業技術総合研究所"
        },
        {
            "sign": "a)",
            "content": "g2124009@fun.ac.jp"
        },
        {
            "sign": "*[1]",
            "content": "うたろ: キミを探す、夏(初音ミク「マジカルミライ2021」プログラミング・コンテスト).https://textalive.jp/apps/Ew3oA5OF9GA4YyMF"
        },
        {
            "sign": "*[2]",
            "content": "catLee: Lyric Trail (初音ミク「マジカルミライ2020」プログラミング・コンテスト).https://textalive.jp/apps/hIuZ6YCsV0If1gBo"
        },
        {
            "sign": "*[3]",
            "content": "zabu: lyric-from-mouth (初音ミク「マジカルミライ2023」プログラミング・コンテスト).https://textalive.jp/apps/OHQeAKG7bIJ3iB8e"
        }
    ],
    "references": [
        {
            "sign": "[1]",
            "content": "Kato, J. and Goto, M.:Lyric App Framework:A Web-Based Framework for Developing InteractiveLyric-Driven Musical Applications, Proceedings of the2023 CHI Conference on Human Factors in Com-puting Systems, CHI ’23, New York, NY, USA, As-sociation for Computing Machinery, (online), DOI:10.1145/3544548.3580931 (2023)."
        },
        {
            "sign": "[2]",
            "content": "小島颯英，柏木敏朗，中小路久美代：MR 環境での楽曲と同期した歌詞表示におけるユーザの注視箇所の分析，情報処理学会研究報告Vol.2024-HCI-209，札幌, 北海道,日本，情報処理学会，pp. 1–7 (2024)."
        },
        {
            "sign": "[3]",
            "content": "小島颯英，中小路久美代，加藤 淳：MR 環境LyricBatheにおけるインタラクティブな歌詞表現のデザインスペースの創出，信学技報HCS2024-79,HIP2024-80 (2025-01)，茨木, 大阪, 日本，電子情報通信学会，pp. 78–83 (2025)."
        },
        {
            "sign": "[4]",
            "content": "Ford, S., Forlizzi, J. and Ishizaki, S.:Kinetic ty-pography: issues in time-based presentation of text,CHI ’97 extended abstracts on Human factors in com-puting systems looking to the future - CHI ’97, At-lanta, Georgia, ACM Press, p. 269 (online), DOI:10.1145/1120212.1120387 (1997)."
        },
        {
            "sign": "[5]",
            "content": "Yokohama, H., Kasihwagi, T., Yamamoto, Y. andNakakoji, K.:[How Different Text Animations Af-fect MR-Based Novel Poetry-Reading Experience] MRwo mochiita dokusho kankyou ni okeru moji no hy-ougen houshiki to shi no inshou no chigai ni kansurukousatsu(in Japanese), Human Interface Symposium2022, pp. 75–80 (2022)."
        },
        {
            "sign": "[6]",
            "content": "Bandyopadhyay, P.: Immersive Space to Think: theRole of 3D Immersive Space in Sensemaking of Tex-tual Data, PhD Thesis, Virginia Tech (2020)."
        },
        {
            "sign": "[7]",
            "content": "Luo,W.,Ellenberg,M. O.,Satkowski,M. andDachselt, R.:Documents in Your Hands:Explor-ing Interaction Techniques for Spatial Arrangementof Augmented Reality Documents, Proceedings of the2025 CHI Conference on Human Factors in Comput-ing Systems, Yokohama Japan, ACM, pp. 1–22 (on-line), DOI: 10.1145/3706598.3713518 (2025)."
        },
        {
            "sign": "[8]",
            "content": "Amini, F., Riche, N. H., Lee, B., Monroy-Hernandez,A. and Irani, P.: Authoring Data-Driven Videos withDataClips, IEEE Transactions on Visualization andComputer Graphics, Vol. 23, No. 1, pp. 501–510 (on-line), DOI: 10.1109/TVCG.2016.2598647 (2017)."
        },
        {
            "sign": "[9]",
            "content": "David, Chung, S.-W. and Caires, C. S.: i-Cube, an(In)tangible Interface for Multi-user Generative ArtCreation, Entertainment Computing – ICEC 2023(Ciancarini, P., Di Iorio, A., Hlavacs, H. and Poggi,F., eds.), Singapore, Springer Nature Singapore, pp.187–192 (2023)."
        },
        {
            "sign": "[10]",
            "content": "Miyagawa, S., Koyama, Y., Kato, J., Goto, M.and Morishima, S.:Placing Music in Space:AStudy on Music Appreciation with Spatial Mapping,Proceedings of the 2018 ACM Conference Compan-ion Publication on Designing Interactive Systems,Hong Kong China, ACM, pp. 39–43 (online), DOI:10.1145/3197391.3205409 (2018)."
        },
        {
            "sign": "[11]",
            "content": "Jeon, J. and Lee, C. H.:SoundMist:Novel In-terface for Spatial Auditory Experience,AdjunctProceedings of the 36th Annual ACM Symposiumon User Interface Software and Technology,SanFrancisco CA USA, ACM, pp. 1–3 (online), DOI:10.1145/3586182.3616622 (2023)."
        },
        {
            "sign": "[12]",
            "content": "Jeon, J. and Lee, C. H.: Sprayable Sound: Exploringthe Experiential and Design Potential of PhysicallySpraying Sound Interaction, Proceedings of the 2025CHI Conference on Human Factors in Computing Sys-tems, Yokohama Japan, ACM, pp. 1–17 (online), DOI:10.1145/3706598.3713786 (2025)."
        },
        {
            "sign": "[13]",
            "content": "Kato, J., Nakano, T. and Goto, M.:TextAlive:Integrated Design Environment for Kinetic Typog-raphy, Proceedings of the 33rd Annual ACM Con-ference on Human Factors in Computing Systems,CHI ’15,New York,NY, USA, Association forComputing Machinery, p. 3403–3412 (online), DOI:10.1145/2702123.2702140 (2015)."
        },
        {
            "sign": "[14]",
            "content": "Suno, Inc.: Suno. https://suno.com/home [2025-06-12]."
        }
    ],
    "warnings": []
}